---
title: 'The Woods Hole Assessment Model (WHAM): Incorporating environmental covariates into a state-space assessment framework'
author: Brian C. Stock^1^, Timothy J. Miller ^1^
date: ''
output:
  pdf_document:
    keep_tex: false
    fig_caption: yes
    number_sections: true
    includes:
      in_header: options.sty
csl: fisheries-research.csl
bibliography: wham-sim.bib
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy=FALSE, tidy.opts=list(width.cutoff=60), warning = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = '../' )
library(knitr)
library(tidyverse)
library(cowplot)
library(ggsidekick)
library(pander)
library(kableExtra)
library(png)
library(forcats)
library(wham)
library(ggplotFL)
library(ggsci)
```

$^1$brian.stock@noaa.gov, timothy.j.miller@noaa.gov, Northeast Fisheries Science Center, National Marine Fisheries Service, 166 Water Street, Woods Hole, MA 02543, USA\

\pagebreak

## Abstract {-}

WHAM is great.

### Keywords {-}

state-space; stock assessment; mixed effects; random effects; time-varying; Template Model Builder (TMB)

\pagebreak

# Introduction  

Grab stuff from NRC and Fish/Climate proposals.

## Context: assessments in the U.S. Northeast

- Long history, high F (pre-data)
- Empirical weight-at-age
- Retrospective patterns
- ASAP3/4
- Operational vs. research-track
- The Northeast U.S. Shelf LME is rapidly changing. Top priority is to "continue development of stock assessment models that include environmental terms" [@hare2016Northeast].

## Motivation #1: advantages of state-space stock assessments

- objective estimation of process errors and data weighting, e.g. $\sigma_R$, instead of ad-hoc
- inherently predict unobserved states, so predicting missing data/years and into the future is natural
- allow for time/age variation in demographic processes while estimating fewer parameters
- natural framework to include environmental time-series
- lower retros and AIC, larger (more realistic) uncertainty compared to SCAAs. Cite ICES state-space if in review.

[@aeberhard2018Review; @miller2016Statespace; @nielsen2014Estimation]

## Motivation #2: allow for environmental effects

- Reduced retrospective patterns
- Lower residual variance

[@miller2016Statespace; @miller2018Evaluating; @oleary2019Understanding]

## How is WHAM different from SAM?

*Not sure where to put this... may be more natural after introducing equations in Methods, some in Discussion. Definitely will be a question in readers' minds so may be good to introduce early?*

Most assessments in the U.S. assume separability in $F_{a,t}$, estimate $F_t$ and $Sel_a$. WHAM does this. SAM estimates $F_{a,t}$ directly. WHAM and SAM also make different separability assumptions for the catch/index data (aggregate total + age comps vs. $C_{a,t}$ directly). Should be similar (?) but could test.

Goal is to replicate ASAP assessments in the U.S. Northeast. Can easily turn on/off random effects.

Observation model is natural for landings data that are measured as total weight plus age composition sampling. Age composition sampling often done separately with survey data.

Treating $F$ and $Sel$ separately can be useful for projections. Oftentimes we want to specify $F$ in projections to calculate a reference point, as opposed to continuing a $F$ time-series process.

## Bias correction

- Analytical obs error. [@aldrin2020Specification].
- Analytical process error. 
- TMB epsilon. [@thorson2016Implementing; @thorson2019Perspective]

Should these all be used?

## Overview

In summary, the NEFSC wants an assessment framework that i) estimates random effects (i.e. a state-space model), ii) includes environmental effects, and iii) is easy to test against status quo SCAA models (ASAP). The objectives of this manuscript are to introduce the WHAM framework and demonstrate unbiasedness in self- and cross-tests.

# Methods

## Model description

### Unobserved states (random effects)

#### Numbers-at-age (survival)

#### Natural mortality ($M$)

#### Selectivity

#### Environmental covariate(s)
##### Time-series model
##### Observation model
##### Link to population

### Data/observation model

#### Catch (agg, age comp)
#### Index (agg, age comp)

## Simulation tests

We used the stocks in Table \ref{tab:stock-list}.

We used R [@rcoreteam2020Language]. WHAM is available as an R package [@miller2020Woods]. OSA residuals.

# Results

Sweet figures.

# Discussion

## Overview

We described WHAM. Sim tests showed no bias in self-tests (when estimation model matched operating model). Some bias in cross-tests.

## Future work

WHAM will be used in upcoming research track assessments. Could transition to operational. Potential to improve several NEFSC assessments.

- 2D AR(1) selectivity. Most assessments in the U.S. assume separability in $F_{a,t}$, i.e. estimate $F_t$ and $Sel_a$. WHAM does this. SAM estimates $F_{a,t}$ directly. WHAM and SAM make different separability assumptions for the catch/index data as well (aggregate total + age comps vs. $C_{a,t}$ directly). Should be similar (?) but could test.
- How many time/age-varying random effects can be estimated simultaneously? @stockthisissueImplementing estimated random effect deviations in survival and $M$, as well as an environmental covariate effect on recruitment.
- Ecov-Recruitment simulation study. How much information does Ecov need to have to be useful?

## Extensions

### Multivariate spatiotemporal environmental data
### Length/growth estimation
### Ecov models

- AR(k)
- splines
- Gaussian process/EDM/Munch/Sugihara

## Conclusion

Development of TMB has facilitated significant advancement in fisheries assessment, allowing us to treat population processes as random effects. A grand challenge in fisheries is to assess and manage stocks in a changing environment. Increasingly have the environmental data. Population time-series are lengthening. WHAM is a step in this direction.

## Acknowledgements {-}

This research was performed while BCS held an NRC Research Associateship award at the NEFSC. NOAA Fish & Climate grant number.

\pagebreak

## Supplementary material {-}

More figures.

\pagebreak

## References {-}

<div id="refs"></div>

\pagebreak

```{r stock-list, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
# get biological par estimates from base models
relB <- relF <- sigR <- rep(NA, 5)
ids <- c("SNEMAYT","butterfish","NScod","ICEherring","GBhaddock")
calc_relF <- function(mod){
  sdrep = summary(mod$sdrep)
	ind.FXSPR <- which(rownames(sdrep) == "log_FXSPR")
	F.t <- sdrep[ind.FXSPR,1]
	ind.faa <- which(rownames(sdrep) == "log_FAA_tot")
	n.yrs <- length(mod$years_full)
	n.ages <- mod$env$data$n_ages
  faa <- matrix(sdrep[ind.faa,1], n.yrs, n.ages)	
  age.full.f <- apply(faa,1, function(x) max(which(x == max(x))))
  full.f <- faa[cbind(seq_along(age.full.f),age.full.f)]
	rel.f <- exp(full.f - F.t)
	return(round(tail(rel.f,1),2))
}
calc_relB <- function(mod){
  sdrep = summary(mod$sdrep)
	ind.SSB.FXSPR <- which(rownames(sdrep) == "log_SSB_FXSPR")
	SSB.t <- exp(sdrep[ind.SSB.FXSPR,1])
  ind.ssb <- which(rownames(sdrep) == "log_SSB")
  ssb <- exp(sdrep[ind.ssb,1])
	rel.ssb <- ssb / SSB.t	
	return(round(tail(rel.ssb,1),2))
}
for(i in 1:length(ids)){
  # if(i==1){
  #   m1 <- readRDS(file.path("results",paste0(ids[i],"_NAA_test"),"m1.rds"))
  # } else { 
  #   m1 <- readRDS(file.path("results","old-incorrect-bias-correction",paste0(ids[i],"_NAA"),"m1.rds"))
  # }
  m1 <- readRDS(file.path("results","old-incorrect-bias-correction",paste0(ids[i],"_NAA"),"m1.rds"))
  sigR[i] <- round(exp(m1$sdrep$par.fixed["log_NAA_sigma"]),2)
  relB[i] <- calc_relB(m1)
  relF[i] <- calc_relF(m1)
}

dat <- data.frame(Stock = c("SNEMA yellowtail flounder", "Butterfish", "North Sea cod", "Icelandic herring", "Georges Bank haddock"),
                  NAA = rep("x",5),
                  M = c("x","x","x","",""),
                  Ecov = c("x","","","",""),
                  n.ages = c(6,5,6,11,9),
                  n.years = c(49,31,54,30,86),
                  NatMort = c("0.2-0.4","1.3","0.2-1.2","0.1","0.2"),
                  sig_R = sigR,
                  relB = relB,
                  relF = relF)

dat %>% dplyr::rename("$\\sigma_R$"="sig_R", "\\# Ages"='n.ages', "\\# Years"='n.years', "$M$"='NatMort', "$\\frac{B}{B_{40}}$"='relB', "$\\frac{F}{F_{40}}$"='relF') %>%
  kable("latex", booktabs = T, escape=F, caption="Stocks used in simulation tests.") %>%
  kable_styling(latex_options=c("basic")) %>%
  add_header_above(c(" "=1, "Modules tested"=3, "Model dim"=2, "Biol. par."=2, "Stock status"=2))
```

<!-- \pagebreak -->
<!-- \newpage -->
\clearpage

```{r, echo = FALSE, results = "asis"}
cat("\\newgeometry{top=1cm}")
```

```{r snemayt-naa, echo=FALSE, message=FALSE, warnings=FALSE, out.width='6in',fig.height=8.5, fig.width=6, fig.cap="Relative error of key quantities estimated for Southern New England-Mid-Atlantic yellowtail flounder using four models of numbers-at-age (NAA) random effects. m1 = only recruitment deviations are random effects (most similar to traditional statistical catch-at-age, SCAA), and deviations are independent and identically distributed (IID). m2 = as m1, but with autocorrelated recruitment deviations (AR1). m3 = all NAA deviations are IID random effects. m4 = as m3, but deviations are correlated by age and year (2D AR1)."}
id = "SNEMAYT_NAA"
res_dir <- file.path(getwd(),"results","old-incorrect-bias-correction",id)
res.files <- list.files(path=res_dir, pattern = "results", full.names = TRUE)
res.list <- lapply(res.files, readRDS)
flatten.nested.list <- function(X) if(is.list(X)) Reduce(c, lapply(X, flatten.nested.list)) else list(X)
results <- do.call(rbind, flatten.nested.list(res.list)) %>% as.data.frame
results <- sapply(results, as.numeric)
results <- as.data.frame(results)
types <- c("OE","OEPE")
mlabs = c("m1: SCAA (iid)","m2: SCAA (AR1_y)","m3: NAA (iid)","m4: NAA (2D AR1)")
tylabs = c("Simulated data: Obs error", "Simulated data: Obs + Process error (new NAA)")
results$om <- factor(results$om, levels=1:4, labels=mlabs)
results$em <- factor(results$em, levels=1:4, labels=mlabs)
results$type <- factor(results$type, levels=1:2, labels=tylabs)
results$em.x <- fct_recode(results$em, m1="m1: SCAA (iid)", m2="m2: SCAA (AR1_y)", m3="m3: NAA (iid)", m4="m4: NAA (2D AR1)")

# calculate relative error
results$SSB.rel = results$SSB_fit / results$SSB_sim
results$SSB.rel.bc = results$SSB_fit_bc / results$SSB_sim
results$F.rel = results$F_fit / results$F_sim
results$F.rel.bc = results$F_fit_bc / results$F_sim
results$relB.rel = results$relB_fit / results$relB_sim
results$relB.rel.bc = results$relB_fit_bc / results$relB_sim
results$relF.rel = results$relF_fit / results$relF_sim
results$relF.rel.bc = results$relF_fit_bc / results$relF_sim
results$catch.rel = results$catch_fit / results$catch_sim
results$catch.rel.bc = results$catch_fit_bc / results$catch_sim

simdata <- lapply(1:4, function(x) readRDS(file.path(getwd(),"data","simdata",id,paste0("simdata_om",x,".rds"))))
results$R.sim = NA
for(om in 1:4){
  for(em in 1:4){
    for(i in 1:100){
      for(ty in 1:2){
        res.ind <- which(results$om == mlabs[om] & results$em == mlabs[em] & results$sim == i & results$ty == tylabs[ty])
        results$R.sim[res.ind] <- simdata[[om]][[i]][[ty]]$NAA[,1]
      }
    }
  }
}
results$R.rel <- results$NAA1 / results$R.sim
results$R.rel.bc <- results$NAA1_bc / results$R.sim

ty=2
# collapse across years, group by om/em
	df.plot <- filter(results, type==levels(results$type)[ty]) %>%
              select(om, em, em.x, SSB.rel, F.rel, relB.rel, relF.rel, R.rel) %>%
              pivot_longer(-c(om,em,em.x), names_to = "variable", values_to = "val") %>%
	            group_by(om, em)
	df.plot$val = df.plot$val - 1 # relative error
	
	df.plot$variable <- factor(df.plot$variable, levels=c("SSB.rel", "F.rel", "relB.rel", "relF.rel", "R.rel"), 
	                       labels=c("SSB", "F", expression(B/B[40]["%"]), expression(F/F[40]["%"]), "Recruitment"))
	df.plot$om2 <- factor(df.plot$om, labels=c(expression(paste("m1:")~paste("SCAA")~paste("(iid)")), 
	                                     expression(paste("m2:")~paste("SCAA (")*AR1[y]*paste(")")), 
            	                         expression(paste("m3:")~paste("NAA")~paste("(iid)")), 
	                                     expression(paste("m4:")~paste("NAA")~paste("(2D AR1)"))))
	df.plot$em2 <- factor(df.plot$em, labels=c(expression(paste("m1:")~paste("SCAA")~paste("(iid)")), 
	                                     expression(paste("m2:")~paste("SCAA (")*AR1[y]*paste(")")), 
            	                         expression(paste("m3:")~paste("NAA")~paste("(iid)")), 
	                                     expression(paste("m4:")~paste("NAA")~paste("(2D AR1)"))))	
                                     	 # "m4: NAA (2D~AR1)"))

	 p <- ggplot(df.plot, aes(x=em.x, y=val)) +
            	  geom_boxplot(aes(fill=em2), outlier.shape = NA) +
            	  scale_fill_jco(name="", labels=lapply(levels(df.plot$em2), function(x) parse(text=x))) +
            	  coord_cartesian(ylim=c(-1,1)) +
                xlab("Estimation model") +
	              ylab(NULL) +
            	  geom_hline(yintercept = 0, linetype=2, color='black') +
	              facet_grid(rows=vars(variable), cols=vars(om2), labeller = label_parsed, switch='y') +
            	  theme_bw() +
            	  theme(legend.position="bottom", strip.background.y = element_blank(), strip.placement = "outside", 
            	        strip.text.y = element_text(size = 12), strip.text.x = element_text(size = 8, margin = margin(3,1,1,1, "pt")),
            	        axis.title.x = element_text(size = 12), axis.text.x = element_text(size = 8),
            	        legend.text = element_text(margin = margin(r = 6, l=1,unit = "pt"), hjust = 0, size=8), legend.box.margin = margin(0,0,0,0), legend.margin = margin(0,0,0,0))
  title <- ggdraw() + draw_label("Operating model", hjust = 0.3, vjust=1) + theme(plot.margin = margin(0, 0, 0, 0))
  plot_grid(title, p, ncol = 1, rel_heights = c(0.045, 1))
```

```{r, echo = FALSE, results = "asis"}
cat("\\restoregeometry")
```

\pagebreak

```{r snemayt-m, echo=FALSE, message=FALSE, warnings=FALSE, out.width='6in',fig.height=8.5, fig.width=6, fig.cap="Relative error of key quantities estimated for Southern New England-Mid-Atlantic yellowtail flounder using three models of natural mortality (\\textit{M}) random effects. m1 = no random effects on M. m2 = \\textit{M} deviations are independent and identically distributed (IID). m3 = \\textit{M} deviations are correlated by age and year (2D AR1)."}
id = "SNEMAYT_M"
res_dir <- file.path(getwd(),"results","old-incorrect-bias-correction",id)
res.files <- list.files(path=res_dir, pattern = "results", full.names = TRUE)
om2em2 <- res.files[4]
res.files <- res.files[-4] # om2/em2 in diff format
res.list <- lapply(res.files, readRDS)
flatten.nested.list <- function(X) if(is.list(X)) Reduce(c, lapply(X, flatten.nested.list)) else list(X)
results <- do.call(rbind, flatten.nested.list(res.list)) %>% as.data.frame
results <- sapply(results, as.numeric)
results <- as.data.frame(results)
results <- rbind(results, readRDS(om2em2))
types <- c("OE","OEPE")
mlabs = c("m1: none","m2: IID","m3: 2D AR1")
n.mods <- length(mlabs)
tylabs = c("Simulated data: Obs error", "Simulated data: Obs + Process error (new NAA)")
results$om <- factor(results$om, levels=1:n.mods, labels=mlabs)
results$em <- factor(results$em, levels=1:n.mods, labels=mlabs)
results$type <- factor(results$type, levels=1:2, labels=tylabs)
results$em.x <- fct_recode(results$em, m1="m1: none", m2="m2: IID", m3="m3: 2D AR1")

# calculate relative error
results$SSB.rel = results$SSB_fit / results$SSB_sim
results$SSB.rel.bc = results$SSB_fit_bc / results$SSB_sim
results$F.rel = results$F_fit / results$F_sim
results$F.rel.bc = results$F_fit_bc / results$F_sim
results$relB.rel = results$relB_fit / results$relB_sim
results$relB.rel.bc = results$relB_fit_bc / results$relB_sim
results$relF.rel = results$relF_fit / results$relF_sim
results$relF.rel.bc = results$relF_fit_bc / results$relF_sim
results$catch.rel = results$catch_fit / results$catch_sim
results$catch.rel.bc = results$catch_fit_bc / results$catch_sim

simdata <- lapply(1:n.mods, function(x) readRDS(file.path(getwd(),"data","simdata",id,paste0("simdata_",id,"_om",x,".rds"))))
results$R.sim = NA
for(om in 1:n.mods){
  for(em in 1:n.mods){
    for(i in 1:100){
      for(ty in 1:2){
        res.ind <- which(results$om == mlabs[om] & results$em == mlabs[em] & results$sim == i & results$ty == tylabs[ty])
        results$R.sim[res.ind] <- simdata[[om]][[i]][[ty]]$NAA[,1]
      }
    }
  }
}
results$R.rel <- results$NAA1 / results$R.sim
results$R.rel.bc <- results$NAA1_bc / results$R.sim

ty=2
# collapse across years, group by om/em
	df.plot <- filter(results, type==levels(results$type)[ty]) %>%
              select(om, em, em.x, SSB.rel, F.rel, relB.rel, relF.rel, R.rel) %>%
              pivot_longer(-c(om,em,em.x), names_to = "variable", values_to = "val") %>%
	            group_by(om, em)
	df.plot$val = df.plot$val - 1 # relative error
	
	df.plot$variable <- factor(df.plot$variable, levels=c("SSB.rel", "F.rel", "relB.rel", "relF.rel", "R.rel"), 
	                       labels=c("SSB", "F", expression(B/B[40]["%"]), expression(F/F[40]["%"]), "Recruitment"))
	df.plot$om2 <- factor(df.plot$om, labels=c(expression(paste("m1:")~paste("none")), 
            	                         expression(paste("m2:")~paste("IID")), 
	                                     expression(paste("m3:")~paste("2D AR1"))))
	df.plot$em2 <- factor(df.plot$em, labels=c(expression(paste("m1:")~paste("none")), 
            	                         expression(paste("m2:")~paste("IID")), 
	                                     expression(paste("m3:")~paste("2D AR1"))))

	 p <- ggplot(df.plot, aes(x=em.x, y=val)) +
            	  geom_boxplot(aes(fill=em2), outlier.shape = NA) +
            	  scale_fill_jco(name="", labels=lapply(levels(df.plot$em2), function(x) parse(text=x))) +
            	  coord_cartesian(ylim=c(-1,1)) +
                xlab("Estimation model") +
	              ylab(NULL) +
            	  geom_hline(yintercept = 0, linetype=2, color='black') +
	              facet_grid(rows=vars(variable), cols=vars(om2), labeller = label_parsed, switch='y') +
            	  theme_bw() +
            	  theme(legend.position="bottom", strip.background.y = element_blank(), strip.placement = "outside", 
            	        strip.text.y = element_text(size = 12), strip.text.x = element_text(size = 10),
            	        axis.title.x = element_text(size = 12), axis.text.x = element_text(size = 10),
            	        legend.text = element_text(margin = margin(r = 6, l=1,unit = "pt"), hjust = 0, size=10), legend.box.margin = margin(0,0,0,0), legend.margin = margin(0,0,0,0))
  title <- ggdraw() + draw_label("Operating model", hjust = 0.25, vjust=1) + theme(plot.margin = margin(0, 0, 0, 0))
  plot_grid(title, p, ncol = 1, rel_heights = c(0.045, 1))
```
